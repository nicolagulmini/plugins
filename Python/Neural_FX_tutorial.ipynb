{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pedalboard\n",
        "!pip install -q keras-tcn --no-dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq14yTy9zwp9",
        "outputId": "268232ec-61b6-4cd9-fc3f-1a13f48f8d28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pedalboard in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pedalboard) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2smStC6vBSI2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from pedalboard.io import AudioFile\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr = 44100\n",
        "\n",
        "N = 400\n",
        "M = 1400"
      ],
      "metadata": {
        "id": "70eef_FX4Z5I"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processSequenceToBatch(sequence, n, m):\n",
        "\n",
        "    lookBackBuffer = np.zeros((2, m))\n",
        "\n",
        "    seqLen = sequence.shape[1]\n",
        "    nSubSequences = math.floor(seqLen/n)\n",
        "\n",
        "    finalBatch = []\n",
        "\n",
        "    for i in range(nSubSequences-1):\n",
        "        subSeq = np.zeros((2, m+n))\n",
        "        subSeq[:,:m] = lookBackBuffer\n",
        "        subSeq[:,m:] = sequence[:,i*n:(i+1)*n]\n",
        "        finalBatch.append(subSeq)\n",
        "        lookBackBuffer = subSeq[:,n:]\n",
        "\n",
        "    return np.array(finalBatch).transpose((0, 2, 1))"
      ],
      "metadata": {
        "id": "YlT9R_GG_Z8Q"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class nnModel:\n",
        "\n",
        "    # choose dilation_rate d and kernel_size k in order to have d*(k-1)=M (pastSamples)\n",
        "\n",
        "    def __init__(self, inputSamples, pastSamples):\n",
        "        self.N = inputSamples\n",
        "        self.M = pastSamples\n",
        "        self.K = 101 # self.M / sum(dilation rates) + 1 = (1400/14)+1 = 101 in order to obtain output dimension = N (input dimension)\n",
        "\n",
        "        input = tf.keras.Input(shape=(N+M, 2))\n",
        "\n",
        "        x = tf.keras.layers.Conv1D(filters=32, kernel_size=self.K, dilation_rate=2, activation='tanh', kernel_initializer='random_normal')(input)\n",
        "        x = tf.keras.layers.Conv1D(filters=32, kernel_size=self.K, dilation_rate=4, activation='relu', kernel_initializer='random_normal')(x)\n",
        "        output = tf.keras.layers.Conv1D(filters=2, kernel_size=self.K, dilation_rate=8, activation='tanh', kernel_initializer='random_normal')(x)\n",
        "\n",
        "        model = tf.keras.models.Model(inputs=input, outputs=output)\n",
        "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mse\")\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def getInfo(self):\n",
        "        self.model.summary()\n",
        "\n",
        "    def trainNetwork(self, x, y, batchSize, epochs, verbose=1):\n",
        "        return self.model.fit(x=x, y=y, batch_size=batchSize, epochs=epochs, verbose=verbose)\n",
        "\n",
        "    def predict(self, batchAudioStereo):\n",
        "        res = self.model.predict(batchAudioStereo)\n",
        "        outputL = []\n",
        "        outputR = []\n",
        "        res = res.transpose((0, 2, 1))\n",
        "        for i in range(res.shape[0]):\n",
        "            for sample in res[i, 0]:\n",
        "                outputL.append(sample)\n",
        "            for sample in res[i, 1]:\n",
        "                outputR.append(sample)\n",
        "        return np.array([np.array(outputL), np.array(outputR)])"
      ],
      "metadata": {
        "id": "DiHFWFqv_T49"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with AudioFile(\"clean.wav\").resampled_to(sr) as i: cleanAudio_mono = i.read(i.frames)\n",
        "with AudioFile(\"effect.wav\").resampled_to(sr) as i: fxAudio = i.read(i.frames)\n",
        "\n",
        "cleanAudio = np.array([cleanAudio_mono[0], cleanAudio_mono[0]])\n",
        "print(cleanAudio.shape)\n",
        "print(fxAudio.shape)\n",
        "\n",
        "X_train = processSequenceToBatch(cleanAudio, N, M)\n",
        "Y_train = processSequenceToBatch(fxAudio, N, M)\n",
        "'''"
      ],
      "metadata": {
        "id": "yAeVQfHYEFIj"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuralNetwork = nnModel(inputSamples=N, pastSamples=M)\n",
        "neuralNetwork.getInfo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwaHqCnM3fS1",
        "outputId": "c4d195cd-93ff-4b6c-c028-2601dfda95af"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_64 (InputLayer)       [(None, 1800, 2)]         0         \n",
            "                                                                 \n",
            " conv1d_112 (Conv1D)         (None, 1600, 32)          6496      \n",
            "                                                                 \n",
            " conv1d_113 (Conv1D)         (None, 1200, 32)          103456    \n",
            "                                                                 \n",
            " conv1d_114 (Conv1D)         (None, 400, 2)            6466      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116418 (454.76 KB)\n",
            "Trainable params: 116418 (454.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with AudioFile(\"loop.wav\").resampled_to(sr) as i: loop_mono = i.read(i.frames)\n",
        "loop = np.array([loop_mono[0], loop_mono[0]])\n",
        "loop = processSequenceToBatch(loop, N, M)\n",
        "\n",
        "output = neuralNetwork.predict(loop)\n",
        "\n",
        "with AudioFile('processed-output.wav', 'w', sr, output.shape[0]) as f: f.write(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug8QTZy23ffk",
        "outputId": "2bfdadee-3ade-47eb-95c3-67a6b199bd8f"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 6s 189ms/step\n"
          ]
        }
      ]
    }
  ]
}